{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "\n",
    "import helper_functions\n",
    "reload(helper_functions)\n",
    "from helper_functions import accuracy_rate, load_data, capacity, get_good_idx, get_slice, get_k_fold_cv_idx, get_x_sequences_ffnn, train, get_all_accuracy_rates, allocate_x_batch_ffnn, quantile_score, get_competition_preds\n",
    "\n",
    "\n",
    "nn_type = 'ffnn'\n",
    "allocate_x_batch = allocate_x_batch_ffnn\n",
    "get_x_sequences = get_x_sequences_ffnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([182918, 16])\n",
      "torch.Size([147205, 1])\n",
      "2016-01-01 20:00:00\n",
      "2017-01-07 20:15:00\n",
      "137893\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2021)\n",
    "\n",
    "case=1\n",
    "x,x_time,y,y_time,time_dif,idx_offset = load_data(case)\n",
    "\n",
    "# Index offset between start and end of training data for one single prediction\n",
    "# i.e. number of quarters of an hour we wish to train on for each sample\n",
    "pred_seq_len = 6*4+1\n",
    "\n",
    "\n",
    "#i=1000\n",
    "#print(target_time[i])\n",
    "#print(x_time[i+idx_offset-pred_seq_len+1:i+idx_offset+1])\n",
    "\n",
    "good_idx = get_good_idx(x,y,idx_offset,pred_seq_len)\n",
    "\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "print(x_time[0])\n",
    "print(y_time[0])\n",
    "print(len(good_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (input_linear): Linear(in_features=400, out_features=50, bias=True)\n",
      "  (output_linear): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (act): ReLU()\n",
      "  (dropout): Dropout(p=0.1)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = x.shape[1] * pred_seq_len\n",
    "hidden_size = 50\n",
    "num_hidden = 2\n",
    "out_size = 1\n",
    "drop_p = 0.1\n",
    "\n",
    "# define network\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()  \n",
    "        \n",
    "        self.input_linear = nn.Linear(in_features=input_size,\n",
    "                                      out_features=hidden_size,\n",
    "                                      bias=True)\n",
    "        self.output_linear = nn.Linear(in_features=hidden_size,\n",
    "                                       out_features=out_size,\n",
    "                                       bias=True)\n",
    "        self.hidden_list = []\n",
    "        for i in range(num_hidden):\n",
    "            self.hidden_list.append(nn.Linear(in_features=hidden_size,\n",
    "                                              out_features=hidden_size,\n",
    "                                              bias=True))\n",
    "        \n",
    "        self.act = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_linear(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.act(x)\n",
    "        for hidden_layer in self.hidden_list:\n",
    "            x = hidden_layer(x)\n",
    "            x = self.dropout(x)\n",
    "            x = self.act(x)\n",
    "        x = self.output_linear(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Epoch: 1\n",
      "Epoch: 2\n",
      "Epoch: 3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tw/2y2pqy7n6bzgwt7b424n6v6m0000gn/T/ipykernel_2536/1581872282.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0moptim_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptim_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgood_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_fold_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mvalid_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/02456_deep_learning_wind_power/helper_functions.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(nn_type, x, y, Net, optim_params, num_epochs, batch_size, good_idx, k_fold_size, idx_offset, pred_seq_len, loss, case)\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0mslce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m                 \u001b[0mx_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_sequences_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mslce\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/GitHub/02456_deep_learning_wind_power/helper_functions.py\u001b[0m in \u001b[0;36mget_x_sequences_ffnn\u001b[0;34m(idx, x_stacked, idx_offset, pred_seq_len, x)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_x_sequences_ffnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_stacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_seq_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mx_stacked\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0midx_offset\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpred_seq_len\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0midx_offset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx_stacked\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# setting hyperparameters and gettings epoch sizes\n",
    "batch_size = 1000\n",
    "num_epochs = 10\n",
    "k_fold_size = 2\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "#loss = nn.L1Loss()\n",
    "\n",
    "\n",
    "optim_params = {'lr': 3e-3, 'weight_decay': 0}\n",
    "train_loss, valid_loss = train(nn_type, x, y, Net, optim_params, num_epochs, batch_size, good_idx, k_fold_size, idx_offset, pred_seq_len, loss, case)\n",
    "valid_loss[0] = np.sqrt(valid_loss[0])\n",
    "\n",
    "#np.savez(outfile, train_loss=train_loss, valid_loss=valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = np.arange(len(train_loss))\n",
    "plt.figure()\n",
    "plt.plot(epoch, train_loss[:,:].mean(axis=-1), 'r', epoch, valid_loss[:,:,:].mean(axis=-1)[0, :], 'b')\n",
    "plt.legend(['Train Loss','Validation Loss'])\n",
    "plt.xlabel('Updates'), plt.ylabel('MSE [normalized units]')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epoch, capacity(case)*np.array(valid_loss[:,:,:].mean(axis=-1)[:-1]).T)\n",
    "plt.legend(['rmse','mae','quantile score'])\n",
    "plt.xlabel('Updates'), plt.ylabel('Loss')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epoch, valid_loss[:,:,:].mean(axis=-1)[-1])\n",
    "plt.xlabel('Updates'), plt.ylabel('Accuracy rate')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = allocate_x_batch(len(good_idx), input_size, pred_seq_len)\n",
    "predictions = net(get_x_sequences(good_idx, x_batch, idx_offset, pred_seq_len, x)).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(y_time[good_idx], capacity(case)*y[good_idx].detach().numpy(), '.', markersize=0.5, label = 'Measured')\n",
    "plt.plot(y_time[good_idx], capacity(case)*predictions,'.', markersize=0.5, label = 'Predicted')\n",
    "lgnd = plt.legend(markerscale=15)    \n",
    "plt.xticks(rotation=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = allocate_x_batch(96, input_size, pred_seq_len)\n",
    "accuracies, times = get_all_accuracy_rates(net, x, y, y_time, x_batch, get_x_sequences, good_idx, idx_offset, pred_seq_len, case)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(times, accuracies)\n",
    "plt.xticks(rotation=30)\n",
    "plt.ylim(0.3,1)\n",
    "plt.show()\n",
    "print('Mean accuracy rate', np.mean(accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day=0\n",
    "save=False\n",
    "predictions = get_competition_preds(day,case,get_x_sequences,allocate_x_batch,input_size,pred_seq_len,net,save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_3_7",
   "language": "python",
   "name": "tf_3_7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
